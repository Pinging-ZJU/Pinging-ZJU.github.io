<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ping Chen</title>

    <meta name="author" content="Ping Chen">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  陈平 (Ping Chen)
                </p>
                <p style="text-align:justify; text-justify:inter-ideograph;">
                I am working toward a Ph.D. with the College of Computer Science and Technology, <a href="https://www.zju.edu.cn/">Zhejiang University, China</a>, where I am advised by <a href="https://shuibing9420.github.io/">Prof. Shuibing He</a> and <a href="https://www.cs.iit.edu/~sun/">Prof. Xian-He Sun</a>.
              </p>
              <p style="text-align:justify; text-justify:inter-ideograph;">
                Up to now, I have published several papers in top journals and conferences in computer systems, such as TC, TPDS, Cluster, and ICPP. Besides, At Zhejiang University, I led a team of over ten members, collaborating closely to develop innovative and practical AI systems. We try to enhance the training, inference, and scheduling efficiency for computer vision, large language models, recommendation systems, and diffusion models.
              </p>

              <p style="text-align:justify; text-justify:inter-ideograph;">
                In my leisure time, I do various types of workout to keep energetic, such as gym (5+ years).
                I like playing basketball (12+ years). As a member of the college basketball team, I actively participated in numerous competitions and secured several medals. I also enjoy sipping wine during my leisure time with my lab mates. :)
                Join me if you're interested.
              </p>
              
                <p style="text-align:center">
                  <a href="zjuchenping@zju.edu.cn">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp; -->
                  <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=Jzbzj_IAAAAJ&hl=zh-CN">Scholar</a> &nbsp;/&nbsp;
                  <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp; -->
                  <a href="https://www.zhihu.com/people/pinging-92">ZhiHu</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/self.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/self.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Experiences on intern</h2>
              <ul>
                <li>Research Intern in the AI System Innovation Lab of HUAWEI Cloud, Hangzhou, China. 
                <p>Advisors: Baoxing Huai, Zhenyu Gu, Zhefeng Wang, and Yi Zheng.</p> 
                <p> August 2023 – Present</p></li>
                <li>Research Intern in the Infrastructure Center of Alibaba Company, Hangzhou, China. 
                <p>Advisors: Yin Du.</p> 
                <p>June 2022 – June 2023</p> </li>
                <li>Research Intern in the Intelligent Supercomputer Center of Zhejiang Lab, Hangzhou, China. 
                <p>Advisors: Yi Qin.</p> 
                <p>May 2021 – May 2022</p> </li>
                
              </ul>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Main Research</h2>
                <p style="text-align:justify; text-justify:inter-ideograph;">
                  My research focuses on Intelligent Computing, Memory Management for AI systems. I am interested in optimizing the AI frameworks by exploring the new characteristics of applications (e.g., CV, NLP, LLM, and Recommendation systems) and new memory/storage devices (e.g., GPU HBM, host main memory, and non-volatile main memory).
                </p>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/CSWAP+.png" alt="b3do" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="Paper/CSWAP+.pdf">
                  <span class="papertitle">Accelerating Tensor Swapping in GPUs With Self-Tuning Compression</span>
                </a>
                <br>
                <strong>Ping Chen</strong>, Shuibing He*, Xuechen Zhang, Shuaiben Chen, Peiyi Hong, Yanlong Yin, Xian-He Sun
                <br>
                <em>IEEE Transactions on Parallel and Distributed Systems (TPDS, CCF-A)</em>, 2022
                <br>
                <a href="Paper/CSWAP+.pdf">Paper</a> / <a href="">Slides</a> 

                <p style="text-align:justify; text-justify:inter-ideograph;">We propose a self-tuning tensor compression framework, named CSWAP+, for improving the virtual memory management of GPUs. It uses GPUs for (de)compression directly and thus has high portability and is minimally dependent on GPU architecture features. Furthermore, it only applies compression on tensors that are deemed to be cost-effective considering their compression ratio, size, and the characteristics of compression algorithms at runtime. Finally, to adapt to DNN models with dense tensors, it also supports cost-effective lossy compression for dense tensors with nearly no model training accuracy degradation. </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/HOME.png" alt="b3do" width="160" height="60" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="Paper/HOME.pdf">
                  <span class="papertitle">HOME: A Holistic GPU Memory Management Framework for Deep Learning</span>
                </a>
                <br>
                Shuibing He (Advisor), <strong>Ping Chen</strong>*, Shuaiben Chen, Zheng Li, Siling Yang, Weijian Chen, Lidan Shou 
                <br>
                <em>IEEE Transactions on Computers (TC, CCF-A)</em>, 2023
                <br>
                <a href="Paper/HOME.pdf">Paper</a> / <a href="">Slides</a> 

                <p style="text-align:justify; text-justify:inter-ideograph;">We propose HOlistic MEmory management (HOME), a new framework for performing tensor placements in large DNN training when GPU memory space is not enough. HOME combines tensor swapping with tensor recomputation to reduce GPU memory footprint. Different from existing work that only considers partial DNN model information, HOME takes the holistic DNN model information into account in tensor placement decisions.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/CSWAP.png" alt="b3do" width="160" height="80" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="Paper/CSWAP.pdf">
                  <span class="papertitle">CSWAP: A Self-Tuning Compression Framework for Accelerating Tensor Swapping in GPUs</span>
                </a>
                <br>
                <strong>Ping Chen</strong>, Shuibing He*, Xuechen Zhang, Shuaiben Chen, Peiyi Hong, Yanlong Yin, Xian-He Sun, Gang Chen
                <br>
                <em>2021 IEEE International Conference on Cluster Computing (CLUSTER, CCF-B)</em>, 2021
                <br>
                <a href="Paper/CSWAP.pdf">Paper</a> / <a href="">Slides</a> 

                <p style="text-align:justify; text-justify:inter-ideograph;">We propose a self-tuning tensor compression framework, named CSWAP, for improving the virtual memory management of GPUs. It has high portability and is minimally dependent on GPU architecture features. Furthermore, its runtime only applies compression on tensors that are deemed to be cost-effective considering their sparsity and size and the characteristics of com- pression algorithms. Finally, our framework is fully automated and can customize the compression policy for different neural network architectures and GPU architectures. </p>
              </td>
            </tr> 

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/Lynx.png" alt="b3do" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="Paper/Lynx.pdf">
                  <span class="papertitle">Optimizing Large Model Training through Overlapped Activation Recomputation</span>
                </a>
                <br>
                <strong>Ping Chen</strong>, Wenjie Zhang, Shuibing He*, Yingjie Gu, Zhuwei Peng, Kexin Huang, Xuan Zhan, Weijian Chen, Yi Zheng, Zhefeng Wang, Yanlong Yin, Gang Chen
                <br>
                <em>arXiv</em>, 2024
                <br>
                <a href="Paper/Lynx.pdf">Paper</a> / <a href="">Slides</a> 

                <p style="text-align:justify; text-justify:inter-ideograph;">We design a new recomputation framework, Lynx, to reduce the overhead by overlapping the recomputation with communication occurring in training pipelines. It consists of an optimal scheduling algorithm (OPT) and a heuristic-based scheduling algorithm (HEU). OPT achieves a global optimum but suffers from a long search time. HEU was designed based on our observation that there are identical structures in large DNN models so that we can apply the same scheduling policy to all identical structures.</p>
              </td>
            </tr> 




            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                  <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>Collaborated Research</h2>
                    <p style="text-align:justify; text-justify:inter-ideograph;">
                      I am eager to contribute to collaborative projects across various fields, including Processing in Memory (PIM), diffusion models, and job scheduling on cloud platforms.
                    </p>
                    </p>
                  </td>
                </tr>
              </tbody></table>
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/impress.png" alt="b3do" width="200", height="100" style="border-style: none">
                  </td>
                  <td width="75%" valign="middle">
                    <a href="">
                      <span class="papertitle">IMPRESS: An Importance-Informed Multi-Tier Prefix KV Storage System for Large Language Model Inference</span>
                    </a>
                    <br>
                    Weijian Chen, Shuibing He, Haoyang Qu, Ruidong Zhang, Siling Yang, <strong>Ping Chen</strong>, Yi Zheng, Baoxing Huai, and Gang Chen
                    <br>
                    <em>Proceedings of the 23rd USENIX Conference on File and Storage Technologies (FAST, CCF-A)</em>, 2025
                    <br>
                    <a href="">Paper</a> / <a href="">Slides</a> 
    
                    <p style="text-align:justify; text-justify:inter-ideograph;">In this paper, we propose IMPRESS, an importance-informed multi-tier prefix KV storage system to reduce I/O delay for LLM inference by only loading important prefix KVs. IMPRESS first leverages the insight that there is significant similarity in important token index sets across attention heads and introduces an I/O-efficient important KV identification algorithm. It then optimizes prefix KV storage and caching through importance-informed KV management, reducing TTFT during model inference. Our experimental results show that IMPRESS can reduce TTFT by up to 2.8× compared to state-of-the-art systems, while maintaining com- parable inference accuracy.</p>
                  </td>
                </tr> 

                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/AutoHet.png" alt="b3do" width="200", height="100" style="border-style: none">
                  </td>
                  <td width="75%" valign="middle">
                    <a href="Paper/AutoHet.pdf">
                      <span class="papertitle">AUTOHET: An Automated Heterogeneous ReRAM-Based Accelerator for DNN Inference</span>
                    </a>
                    <br>
                    Tong Wu, Shuibing He*, Jianxin Zhu, Weijian Chen, Siling Yang, <strong>Ping Chen</strong>, Yanlong Yin, Xuechen Zhang, Xian-He Sun, Gang Chen
                    <br>
                    <em>International Conference on Parallel Processing (ICPP, CCF-B)</em>, 2024
                    <br>
                    <a href="Paper/AutoHet.pdf">Paper</a> / <a href="">Slides</a> 
    
                    <p style="text-align:justify; text-justify:inter-ideograph;">We propose AutoHet, an automated heterogeneous ReRAM-based accelerator with varied-size crossbars for different DNN layers. To achieve both high crossbar utilization and energy efficiency, AutoHet uses a reinforcement learning algorithm to automatically determine the proper crossbar configuration for each DNN layer. Additionally, AutoHet introduces rectangle crossbars and a tile-shared crossbar allocation scheme to reduce crossbar wastage and energy consumption.</p>
                  </td>
                </tr> 

          </tbody></table>

        

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
              <tr>
                <td>
                  <h2>Miscellanea</h2>
                </td>
              </tr>
            </tbody></table>
            <table width="100%" align="center" border="0" cellpadding="20"><tbody>
              
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/patent.png" alt="b3do" width="160" style="border-style: none"></td>
                <td width="75%" valign="center">
                    <a>Patents for DNN I/O Optimization</a>
                    <ul>
                      <li><a>基于序列可预测的并行深度学习训练数据输入方法和系统.</a></li>
                      <li><a>面向异构内存设备的深度学习图片数据预处理方法及系统.</a></li>
                      <li><a>面向异构内存设备的深度学习Embedding数据高效处理系统及方法.</a></li>
                    </ul>

                    <a>Patents for GPU Memory Optimization</a>
                    <ul>
                      <li><a>基于Tensor访问的深度学习内存管理方法及系统.</a></li>
                      <li><a>基于神经网络中数据稀疏特性的智能训练加速方法及系统.</a></li>
                      <li><a>基于神经网络中数据稠密特性的智能训练加速方法及系统.</a></li>
                      <li><a>一种基于强化学习内存调度决策的模型训练方法及系统.</a></li>
                      <li><a>基于非易失性内存的推荐系统网络高效训练方法.</a></li>
                      <li><a>一种基于自适应重计算并行策略的大模型显存优化方法 (待实审).</a></li>
                      <li><a>一种重计算感知的自适应模型拆分训练方法 (待实审).</a></li>
                      <li><a>针对大语言模型推理基于分布式NPU池化的KV Cache系统方法 (待实审).</a></li>
                    </ul>
                    
                    <a>Patents for Checkpointing</a>
                    <ul>
                      <li><a>面向神经网络检查点数据的智能压缩存储方法和系统.</a></li>
                    </ul>

                    <a>Patents for Scheduling</a>
                    <ul>
                      <li><a>任务调度方法、装置、电子设备和存储介质.</a></li>
                      <li><a>一种延迟需求感知的DNN推理池化资源分配方法 (待实审).</a></li>
                      <li><a>面向异构池化场景的资源抽象与预测系统 (待实审).</a></li>
                      <li><a>面向异构池化场景的高效资源调度方法 (待实审).</a></li>
                    </ul>

                  <a>5 Chinese Software Copyright</a>
                  <br>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/nation.png" alt="b3do" width="160" style="border-style: none"></td>
                <td width="75%" valign="center">
                  <a>National Scholarship, 2023-2024</a>
                  <br>
                  <a>National Scholarship, 2017-2018</a>
                  <br>
                  <a>The 2nd National College Student Information Storage Technology Competition, Silver Award, 2024</a>
                  <br>
                  <a>China International College Students' Innovation Competition, Silver Award, 2024</a>
                  <br>
                  <a>National Encouragement Scholarship, 2016-2017</a>
                  <br>
                  <a>National Encouragement Scholarship, 2017-2018</a>
                  <br>
                  <a>Outstanding Graduate, 2019</a>
                  <br>
                  <a>Outstanding Graduation Design, 2019</a>
                  <br>
                  <a>Others...</a>
                  <br>
                </td>
              </tr>

              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
                <tr>
                  <td>
                    <h2>Life</h2>
                  </td>
                </tr>
              </tbody></table>
              <table width="100%" align="center" border="0" cellpadding="20"><tbody>
                
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/meeting.jpg" alt="b3do" width="160" height="110"  style="border-style: none"></td>
                  <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/metal.jpg" alt="b3do" width="160" height="110" style="border-style: none"></td>
                  <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/life.png" alt="b3do" width="160" height="110"  style="border-style: none"></td>
                  <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/life2.png" alt="b3do" width="160" height="110"  style="border-style: none"></td>
                  <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/climb.jpg" alt="b3do" width="160" height="110"  style="border-style: none"></td>
                  <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/basketball1.jpg" alt="b3do" width="160" height="110"  style="border-style: none"></td>
                  <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/basketball2.jpg" alt="b3do" width="160" height="110"  style="border-style: none"></td>

                </tr>
            
          </tbody></table>
  
        </td>
      </tr>
    </table>
  </body>
</html>

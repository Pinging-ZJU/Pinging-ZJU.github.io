<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ping Chen</title>

    <meta name="author" content="Ping Chen">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  陈平 (Ping Chen)
                </p>
                <p style="text-align:justify; text-justify:inter-ideograph;">
                I am working toward a Ph.D. with the College of Computer Science and Technology, <a href="https://www.zju.edu.cn/">Zhejiang University, China</a>, where I was advised by <a href="https://shuibing9420.github.io/">Shuibing He</a> and <a href="https://www.cs.iit.edu/~sun/">Xian-He Sun</a>.
              </p>
              <p style="text-align:justify; text-justify:inter-ideograph;">
                Up to now, I have published several papers in top journals and conferences in computer systems, such as TC, TPDS, Cluster, and ICPP. Besides, At Zhejiang University, I led a team of over ten members, collaborating closely to develop innovative and practical AI systems.
              </p>

              <p style="text-align:justify; text-justify:inter-ideograph;">
                In my leisure time, I do various types of workout to keep energetic, such as gym (5+ years).
                I like playing basketball (12+ years). As a member of the college basketball team, I actively participated in numerous competitions and secured several medals. Join me if you're interested.
              </p>
              
                <!-- <p style="text-align:center">
                  <a href="mailto:jonbarron@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/jonbarron/">Github</a>
                </p> -->
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/self.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/self.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Experiences on intern</h2>
              <ul>
                <li>Research Intern in the AI System Innovation Lab of HUAWEI Cloud, Hangzhou, China. 
                <p>Advisors: Baoxing Huai, Zhenyu Gu, Zhefeng Wang, and Yi Zheng.</p> 
                <p> August 2023 – Present</p></li>
                <li>Research Intern in the Infrastructure Center of Alibaba Company, Hangzhou, China. 
                <p>Advisors: Yin Du.</p> 
                <p>June 2022 – June 2023</p> </li>
                <li>Research Intern in the Intelligent Supercomputer Center of Zhejiang Lab, Hangzhou, China. 
                <p>Advisors: Yi Qin.</p> 
                <p>May 2021 – May 2022</p> </li>
                
              </ul>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Main Research</h2>
                <p style="text-align:justify; text-justify:inter-ideograph;">
                  My research focuses on Intelligent Computing, Memory Management for AI systems. I am interested in optimizing the AI frameworks by exploring the new characteristics of applications (e.g., CV, NLP, LLM, and Recommendation systems) and new memory/storage devices (e.g., GPU HBM, host main memory, and non-volatile main memory).
                </p>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/CSWAP+.png" alt="b3do" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="Paper/CSWAP+.pdf">
                  <span class="papertitle">Accelerating Tensor Swapping in GPUs With Self-Tuning Compression</span>
                </a>
                <br>
                <strong>Ping Chen</strong>, Shuibing He*, Xuechen Zhang, Shuaiben Chen, Peiyi Hong, Yanlong Yin, Xian-He Sun
                <br>
                <em>IEEE Transactions on Parallel and Distributed Systems (TPDS, CCF-A)</em>, 2022
                <br>
                <a href="Paper/CSWAP+.pdf">Paper</a> / <a href="">Slides</a> 

                <p style="text-align:justify; text-justify:inter-ideograph;">We propose a self-tuning tensor compression framework, named CSWAP+, for improving the virtual memory management of GPUs. It uses GPUs for (de)compression directly and thus has high portability and is minimally dependent on GPU architecture features. Furthermore, it only applies compression on tensors that are deemed to be cost-effective considering their compression ratio, size, and the characteristics of compression algorithms at runtime. Finally, to adapt to DNN models with dense tensors, it also supports cost-effective lossy compression for dense tensors with nearly no model training accuracy degradation. </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/HOME.png" alt="b3do" width="160" height="60" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="Paper/HOME.pdf">
                  <span class="papertitle">HOME: A Holistic GPU Memory Management Framework for Deep Learning</span>
                </a>
                <br>
                Shuibing He (Advisor), <strong>Ping Chen</strong>*, Shuaiben Chen, Zheng Li, Siling Yang, Weijian Chen, Lidan Shou 
                <br>
                <em>IEEE Transactions on Computers (TC, CCF-A)</em>, 2023
                <br>
                <a href="Paper/HOME.pdf">Paper</a> / <a href="">Slides</a> 

                <p style="text-align:justify; text-justify:inter-ideograph;">We propose HOlistic MEmory management (HOME), a new framework for performing tensor placements in large DNN training when GPU memory space is not enough. HOME combines tensor swapping with tensor recomputation to reduce GPU memory footprint. Different from existing work that only considers partial DNN model information, HOME takes the holistic DNN model information into account in tensor placement decisions.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/CSWAP.png" alt="b3do" width="160" height="80" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="Paper/CSWAP.pdf">
                  <span class="papertitle">CSWAP: A Self-Tuning Compression Framework for Accelerating Tensor Swapping in GPUs</span>
                </a>
                <br>
                <strong>Ping Chen</strong>, Shuibing He*, Xuechen Zhang, Shuaiben Chen, Peiyi Hong, Yanlong Yin, Xian-He Sun, Gang Chen
                <br>
                <em>2021 IEEE International Conference on Cluster Computing (CLUSTER)</em>, 2021
                <br>
                <a href="Paper/CSWAP.pdf">Paper</a> / <a href="">Slides</a> 

                <p style="text-align:justify; text-justify:inter-ideograph;">We propose a self-tuning tensor compression framework, named CSWAP, for improving the virtual memory management of GPUs. It has high portability and is minimally dependent on GPU architecture features. Furthermore, its runtime only applies compression on tensors that are deemed to be cost-effective considering their sparsity and size and the characteristics of com- pression algorithms. Finally, our framework is fully automated and can customize the compression policy for different neural network architectures and GPU architectures. </p>
              </td>
            </tr> 

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/Lynx.png" alt="b3do" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="Paper/Lynx.pdf">
                  <span class="papertitle">Optimizing Large Model Training through Overlapped Activation Recomputation</span>
                </a>
                <br>
                <strong>Ping Chen</strong>, Wenjie Zhang, Shuibing He*, Yingjie Gu, Zhuwei Peng, Kexin Huang, Xuan Zhan, Weijian Chen, Yi Zheng, Zhefeng Wang, Yanlong Yin, Gang Chen
                <br>
                <em>arXiv</em>, 2024
                <br>
                <a href="Paper/Lynx.pdf">Paper</a> / <a href="">Slides</a> 

                <p style="text-align:justify; text-justify:inter-ideograph;">We design a new recomputation framework, Lynx, to reduce the overhead by overlapping the recomputation with communication occurring in training pipelines. It consists of an optimal scheduling algorithm (OPT) and a heuristic-based scheduling algorithm (HEU). OPT achieves a global optimum but suffers from a long search time. HEU was designed based on our observation that there are identical structures in large DNN models so that we can apply the same scheduling policy to all identical structures.</p>
              </td>
            </tr> 




            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                  <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>Collaborated Research</h2>
                    <p style="text-align:justify; text-justify:inter-ideograph;">
                      I am eager to contribute to collaborative projects across various fields, including Processing in Memory (PIM), diffusion models, and job scheduling on cloud platforms.
                    </p>
                    </p>
                  </td>
                </tr>
              </tbody></table>
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/AutoHet.png" alt="b3do" width="200", height="100" style="border-style: none">
                  </td>
                  <td width="75%" valign="middle">
                    <a href="Paper/AutoHet.pdf">
                      <span class="papertitle">AUTOHET: An Automated Heterogeneous ReRAM-Based Accelerator for DNN Inference</span>
                    </a>
                    <br>
                    Tong Wu, Shuibing He*, Jianxin Zhu, Weijian Chen, Siling Yang, <strong>Ping Chen</strong>, Yanlong Yin, Xuechen Zhang, Xian-He Sun, Gang Chen
                    <br>
                    <em>International Conference on Parallel Processing (ICPP)</em>, 2024
                    <br>
                    <a href="Paper/AutoHet.pdf">Paper</a> / <a href="">Slides</a> 
    
                    <p style="text-align:justify; text-justify:inter-ideograph;">We propose AutoHet, an automated heterogeneous ReRAM-based accelerator with varied-size crossbars for different DNN layers. To achieve both high crossbar utilization and energy efficiency, AutoHet uses a reinforcement learning algorithm to automatically determine the proper crossbar configuration for each DNN layer. Additionally, AutoHet introduces rectangle crossbars and a tile-shared crossbar allocation scheme to reduce crossbar wastage and energy consumption.</p>
                  </td>
                </tr> 

          </tbody></table>

        

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
              <tr>
                <td>
                  <h2>Miscellanea</h2>
                </td>
              </tr>
            </tbody></table>
            <table width="100%" align="center" border="0" cellpadding="20"><tbody>
              
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/patent.png" alt="b3do" width="160" style="border-style: none"></td>
                <td width="75%" valign="center">
                  <a>14 Chinese Patents</a>
                  <br>
                  <a>5 Chinese Software Copyright</a>
                  <br>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/nation.png" alt="b3do" width="160" style="border-style: none"></td>
                <td width="75%" valign="center">
                  <a>National scholarship, 2023-2024</a>
                  <br>
                  <a>National scholarship, 2017-2018</a>
                  <br>
                  <a>China International College Students' Innovation Competition, Silver Award, 2024</a>
                  <br>
                  <a>National Encouragement scholarship, 2016-2017</a>
                  <br>
                  <a>National Encouragement scholarship, 2017-2018</a>
                  <br>
                  <a>Outstanding Graduate, 2019</a>
                  <br>
                  <a>Outstanding Graduation Design, 2019</a>
                  <br>
                  <a>Others...</a>
                  <br>
                </td>
              </tr>

              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
                <tr>
                  <td>
                    <h2>Life</h2>
                  </td>
                </tr>
              </tbody></table>
              <table width="100%" align="center" border="0" cellpadding="20"><tbody>
                
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/meeting.jpg" alt="b3do" width="160" height="110"  style="border-style: none"></td>
                  <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/metal.jpg" alt="b3do" width="160" height="110" style="border-style: none"></td>
                  <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/life.png" alt="b3do" width="160" height="110"  style="border-style: none"></td>
                  <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/life2.png" alt="b3do" width="160" height="110"  style="border-style: none"></td>
                  <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/climb.jpg" alt="b3do" width="160" height="110"  style="border-style: none"></td>
                  <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/basketball1.jpg" alt="b3do" width="160" height="110"  style="border-style: none"></td>
                  <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/basketball2.jpg" alt="b3do" width="160" height="110"  style="border-style: none"></td>

                </tr>
            
          </tbody></table>
  
        </td>
      </tr>
    </table>
  </body>
</html>
